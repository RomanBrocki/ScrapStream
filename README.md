# ScrapNovel

**ScrapNovel** Ã© uma aplicaÃ§Ã£o web baseada em Streamlit para fazer scraping automatizado de web novels usando Selenium. O conteÃºdo extraÃ­do Ã© tratado, limpo e compilado em um eBook `.docx`.

---

## ğŸ“ˆ Funcionalidades

### MÃ³dulo Web (Streamlit)

* Interface elegante e responsiva para entrada de dados.
* Inicia scraping com feedback visual e animaÃ§Ãµes.
* Gera eBooks em `.docx` com tÃ­tulos formatados.

### Scraper (core: `novel_scraper.py`)

* Navega entre capÃ­tulos via botÃ£o "prÃ³ximo".
* Substitui expressÃµes predefinidas (anti-spam/watermark).
* Remove censura por pontos ("s.e.x" â†’ "sex").
* Gera log com ocorrÃªncias encontradas.

### Scripts Auxiliares

* `apaga_duplicados.py`: remove capÃ­tulos repetidos no `.docx` e gera log.
* `desfaz_censura.py`: remove censura por pontos.
* `limpa_docx.py`: aplica remoÃ§Ãµes e substituiÃ§Ãµes com base no `pattern.py`.

---

## âš™ï¸ InstalaÃ§Ã£o RÃ¡pida

```bash
# Clone o repositÃ³rio
git clone https://github.com/RomanBrocki/ScrapStream.git

# Crie e ative o ambiente virtual (opcional)
python -m venv env
source env/bin/activate  # ou env\Scripts\activate no Windows

# Instale as dependÃªncias
pip install -r requirements.txt
```

---

## ğŸ”§ ConfiguraÃ§Ã£o do Scraper

Edite o arquivo `config.py` para definir:

```python
from selenium.webdriver.common.by import By

config = {
    'profile': r"caminho/para/perfil/chrome",
    'author': 'ScrapNovel',
    'chapter_title_selector': (By.CLASS_NAME, 'chr-text'),
    'chapter_content_selector': (By.ID, 'chr-content'),
    'next_chapter_selector': (By.ID, 'next_chap')
}
```

---

## ğŸš€ Executando a aplicaÃ§Ã£o

```bash
streamlit run app.py
```

Acesse via navegador: [http://localhost:8501](http://localhost:8501)

---

## ğŸ”® Tutorial passo a passo

1. **Execute o app com Streamlit**:

   ```bash
   streamlit run app.py
   ```

2. **Abra o navegador** em `http://localhost:8501`

3. **Preencha os campos**:

   * Nome do eBook
   * URL do primeiro capÃ­tulo
   * URL do Ãºltimo capÃ­tulo
   * Caminho para salvar o arquivo `.docx`

4. **Clique em "Iniciar Scrap"**

   * Um GIF serÃ¡ exibido enquanto o scraping ocorre.
   * Ao final, uma mensagem de sucesso aparecerÃ¡ com detalhes e o log.

---

## ğŸ“‚ Estrutura de Arquivos

* `app.py`: Interface Streamlit
* `novel_scraper.py`: LÃ³gica de scraping
* `config.py`: ConfiguraÃ§Ã£o de seletores e perfil do navegador
* `pattern.py`: Lista de expressÃµes a remover
* `desfaz_censura.py`: Remove censura com pontos
* `apaga_duplicados.py`: Remove capÃ­tulos duplicados
* `limpa_docx.py`: Aplica padrÃµes de limpeza com `pattern`
* `assets/`: Imagens e GIFs para UI
* `requirements.txt`: DependÃªncias

---

## ğŸ“Š DependÃªncias

```txt
selenium
undetected_chromedriver
webdriver-manager(nÃ£o recomendado)
python-docx
streamlit
```

---

## ğŸŒ Scripts Avulsos

Utilize diretamente via terminal para tratar arquivos `.docx` existentes:

```bash
python apaga_duplicados.py
python desfaz_censura.py
python limpa_docx.py
```

---

Projeto desenvolvido por Roman W. Brocki com foco em automaÃ§Ã£o, praticidade e refinamento de eBooks gerados a partir de web novels.
