# ğŸ“š ScrapNovel

**ScrapNovel** Ã© uma aplicaÃ§Ã£o web baseada em **Streamlit** para scraping automatizado de web novels. Utiliza **Selenium com `undetected_chromedriver`** para contornar bloqueios como Cloudflare e compila os capÃ­tulos extraÃ­dos em um eBook `.docx` limpo e legÃ­vel.

---

## ğŸ“Š Funcionalidades

### ğŸ”¹ MÃ³dulo Web (`app.py`)

* Interface responsiva com Streamlit
* Entrada intuitiva dos dados (nome do eBook, URLs, saÃ­da)
* Feedback visual com animaÃ§Ã£o de progresso
* GeraÃ§Ã£o automatizada de `.docx` com estrutura e tÃ­tulos formatados

### ğŸ”¹ NÃºcleo do Scraper (`novel_scraper.py`)

* Todas as operaÃ§Ãµes centralizadas em uma **classe `NovelScraper`**
* NavegaÃ§Ã£o automÃ¡tica capÃ­tulo a capÃ­tulo via botÃ£o "PrÃ³ximo"
* SubstituiÃ§Ãµes personalizadas com base em `pattern.py`
* Remove censura por pontos (ex.: `s.e.x` â†’ `sex`)
* Gera log detalhado com expressÃµes tratadas
* **FunÃ§Ã£o `scrape_chapters()` adaptada para contornar o Cloudflare**, com lÃ³gica de retry, espera e scrolldown

### ğŸ”¹ Scripts Auxiliares

* `apaga_duplicados.py`: remove capÃ­tulos repetidos no `.docx`
* `desfaz_censura.py`: limpa censura por pontos em arquivos existentes
* `limpa_docx.py`: aplica as substituiÃ§Ãµes definidas em `pattern.py`

---

## âš™ï¸ InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/RomanBrocki/ScrapStream.git

# Crie e ative o ambiente virtual (opcional)
python -m venv env
source env/bin/activate  # Linux/macOS
env\Scripts\activate     # Windows

# Instale as dependÃªncias
pip install -r requirements.txt
```

---

## ğŸ› ï¸ ConfiguraÃ§Ã£o

Edite o arquivo `config.py` para definir o perfil do Chrome e os seletores CSS/ID usados nos capÃ­tulos:

```python
from selenium.webdriver.common.by import By

config = {
    'profile': r"caminho/para/perfil/chrome",
    'author': 'ScrapNovel',
    'chapter_title_selector': (By.CLASS_NAME, 'chr-text'),
    'chapter_content_selector': (By.ID, 'chr-content'),
    'next_chapter_selector': (By.ID, 'next_chap')
}
```

---

## ğŸš€ Como Executar

```bash
streamlit run app.py
```

Abra no navegador: [http://localhost:8501](http://localhost:8501)

---

## ğŸ“‹ Tutorial RÃ¡pido

1. Execute o app com `streamlit run app.py`
2. Preencha:

   * Nome do eBook
   * URL do primeiro capÃ­tulo
   * URL do Ãºltimo capÃ­tulo
   * Caminho para salvar o `.docx`
3. Clique em **"Iniciar Scrap"**
4. Acompanhe o progresso via animaÃ§Ã£o (GIF)
5. Ao final, uma mensagem de sucesso serÃ¡ exibida com o log salvo

---

## ğŸ“‚ Estrutura do Projeto

| Arquivo/Pasta         | DescriÃ§Ã£o                                            |
| --------------------- | ---------------------------------------------------- |
| `app.py`              | Interface em Streamlit                               |
| `novel_scraper.py`    | LÃ³gica de scraping (classe `NovelScraper`)           |
| `config.py`           | ConfiguraÃ§Ãµes de scraping e perfil do Chrome         |
| `pattern.py`          | ExpressÃµes e palavras a serem removidas/substituÃ­das |
| `desfaz_censura.py`   | Remove censura por pontos                            |
| `apaga_duplicados.py` | Elimina capÃ­tulos repetidos                          |
| `limpa_docx.py`       | Aplica padrÃ£o de limpeza em `.docx`                  |
| `assets/`             | Imagens e animaÃ§Ãµes para interface                   |
| `requirements.txt`    | Lista de dependÃªncias do projeto                     |

---

## ğŸ“¦ DependÃªncias

* `selenium`
* `undetected-chromedriver`
* `streamlit`
* `python-docx`

> âš ï¸ `webdriver-manager` estÃ¡ incluÃ­do, mas **nÃ£o recomendado**, pois nÃ£o contorna bloqueios como o Cloudflare.

---

## ğŸ§¹ Scripts Avulsos

Execute no terminal para tratar `.docx` existentes:

```bash
python apaga_duplicados.py
python desfaz_censura.py
python limpa_docx.py
```

---

## ğŸ‘¨â€ğŸ’» Autor

Desenvolvido por **Roman W. Brocki**, com foco em automaÃ§Ã£o, praticidade e refinamento textual para eBooks extraÃ­dos de web novels.

---

